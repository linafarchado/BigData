{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b08678-1dfd-419c-96f3-6b783ad4c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f507db7-a7b5-4eab-975b-b24876224d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle(\"../../BigData/bourse/data/boursorama/2022/compA 2022-12-30 16:32:02.049716.bz2\")\n",
    "#df\n",
    "spec = \"2020-01-01 14:52\"\n",
    "year = spec.split(\"-\")[0]\n",
    "\n",
    "folder_path = \"../data/boursorama/\" + year + \"/\"\n",
    "\n",
    "file_paths = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "  # Check if filename contains the desired date\n",
    "  if spec in filename:\n",
    "    # Construct the full path\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    file_paths.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ae0729-456a-4291-9a43-6a77d03ad058",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "for file_path in file_paths:\n",
    "  # Read the CSV file into a DataFrame\n",
    "  df = pd.read_pickle(file_path)\n",
    "  data_frames.append(df)\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame (optional)\n",
    "df_combined = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# nan_rows = df_combined[df_combined.isna().any(axis=1)]\n",
    "\n",
    "# print(\"length: \" + str(len(nan_rows)))\n",
    "# if not nan_rows.empty:\n",
    "#   print(\"Rows containing NaN values:\")\n",
    "#   print(nan_rows)\n",
    "# else:\n",
    "#   print(\"No rows contain NaN values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a6f307-07e0-451a-900b-797615941c55",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3780862366.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_combined.tail(400)head(50)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_combined.tail(400)head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de5a7a0-0c57-42b2-8b42-de840ff0d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df_combined.groupby(\"name\")\n",
    "\n",
    "for name, group_df in grouped_df:\n",
    "    for index, row in group_df.iterrows():\n",
    "        if \"(c)\" in str(row[\"last\"]):\n",
    "            df_combined.loc[index, \"last\"] = row[\"last\"][:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f38c7-849b-460a-95ef-22bd463c9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group_df in df_combined.groupby(\"name\"):\n",
    "    if (name == \"VSME\"):\n",
    "        print(group_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e237a-7b5e-4255-86fe-c0138fef9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop_duplicates()\n",
    "#df = df.dropna()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589282ab-1739-404e-a736-9f3f30fe8895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
